{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/irtm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[np.array([len(str(c)) >= 100 for c in df['content']]) & np.array([cls in ['euclid', 'keter', 'safe'] for cls in df['object_class']])].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['content'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa2 import get_token\n",
    "corpus = []\n",
    "for i in range(len(documents)) :\n",
    "    corpus.append(' '.join(get_token(documents[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF_VECTORIZER = TfidfVectorizer()\n",
    "TF_IDF_vector = TFIDF_VECTORIZER.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TF_IDF_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.decomposition.MiniBatchSparsePCA\n",
    "# from sklearn.datasets import make_friedman1\n",
    "# from sklearn.decomposition import MiniBatchSparsePCA\n",
    "from sklearn.manifold import TSNE\n",
    "transformer = TSNE(n_components=2, n_iter=250, random_state=1126, n_jobs=-1)\n",
    "# transformer = MiniBatchSparsePCA(n_components=2, batch_size=50,random_state=0)\n",
    "transformer.fit(a)\n",
    "MiniBatchSparsePCA(...)\n",
    "X_transformed = transformer.transform(a)\n",
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_transformed[0],X_transformed[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(metric='euclidean' , eps = 1.2 , min_samples = 2)\n",
    "dbscan.fit(TF_IDF_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "print(Counter(dbscan.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = []\n",
    "for i in range(0 , 254) :\n",
    "    cluster.append([])\n",
    "    for j in range(len(result)) :\n",
    "        if(result[j] == (i - 1)) :\n",
    "            cluster[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cluster)) :\n",
    "    print(cluster[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means\n",
    "from sklearn.cluster import KMeans\n",
    "n_clusters = 20\n",
    "cost = []\n",
    "for i in range(2,n_clusters):    \n",
    "    kmeans = KMeans(n_clusters=i)\n",
    "    kmeans.fit(TF_IDF_vector)\n",
    "    cost.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = range(2,n_clusters)\n",
    "plt.plot(x,cost, 'bx-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_n_clusters = 15\n",
    "final_kmeans = KMeans(final_n_clusters)\n",
    "final_kmeans.fit(TF_IDF_vector)\n",
    "order_centroids = final_kmeans.cluster_centers_.argsort()[:,::-1]\n",
    "Top_Term_Cluster = [[] for i in range(20)]\n",
    "print(\"----  Top Terms of Each Cluster ----\")\n",
    "for i in range(final_n_clusters):\n",
    "    # print(\"\\n\\nCluster %d keywords: \" % (i+1))\n",
    "    for ind in order_centroids[i, :20]:\n",
    "        #print(TFIDF_vectorizer.get_feature_names()[ind])\n",
    "        Top_Term_Cluster[i].append(TFIDF_VECTORIZER.get_feature_names()[ind])\n",
    "for i in range(15):\n",
    "    print(f'Top Terms for cluster {i+1}')\n",
    "    print(Top_Term_Cluster[i])\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
