{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/irtm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df['object_class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['object_class']!='thaumiel') & (df['object_class']!='neutralized')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[len(str(c)) < 100 for c in df['content']]]\n",
    "df = df[np.array([len(str(c)) >= 100 for c in df['content']]) & np.array([cls in ['euclid', 'keter', 'safe'] for cls in df['object_class']])].reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list = [ [] for i in range(df.shape[0])]\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    \n",
    "    df['content'][row] = df['content'][row].replace('\\n',' ')\n",
    "    tokens = df['content'][row].split()\n",
    "    \n",
    "    for ID in range(df.shape[0]):\n",
    "        if(df['title'][ID] in tokens and ID != row):\n",
    "            adjacency_list[row].append(ID)\n",
    "    \n",
    "    #print(adjacency_list[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for a in adjacency_list:\n",
    "    if(a != []):\n",
    "        print(a)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(adjacency_list)):\n",
    "    adjacency_list[i] = list(adjacency_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list_correct = []\n",
    "startPoint = []\n",
    "count = 0\n",
    "\n",
    "for i in range(len(adjacency_list)):\n",
    "    if(adjacency_list[i] != []):\n",
    "        a = adjacency_list[i].copy()\n",
    "        for node in a:\n",
    "            pair = (i,node)\n",
    "            startPoint.append(i)\n",
    "            adjacency_list_correct.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G=nx.Graph()\n",
    "G.add_nodes_from(startPoint)\n",
    "G.add_edges_from(adjacency_list_correct)\n",
    "print(\"Nodes of graph: \")\n",
    "print(G.nodes())\n",
    "print(\"Edges of graph: \")\n",
    "print(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G,node_size = 10)\n",
    "plt.savefig(\"simple_path.png\") # save as png\n",
    "plt.show() # display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs = list(nx.connected_components(G))\n",
    "f = open('connected components.txt','w')\n",
    "for cc in ccs:\n",
    "    cc = list(cc)\n",
    "    if len(cc) > 2:\n",
    "        for c in cc:\n",
    "            f.write(str(c)+' ')\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa2 import make_dict\n",
    "# dic = make_dict(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa2 import save_dict\n",
    "# save_dict(dic, 'dictionary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa2 import create_vector\n",
    "# create_vector(df['content'], list(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pa3_NB import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = pd.factorize(df.object_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.object_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adj_rating'] = df['rating']**(1/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['adj_rating'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_class = []\n",
    "for i in range(len(df['rating'])):\n",
    "    if df['rating'][i] <= 60 :\n",
    "        rating_class.append('class_1')\n",
    "    elif df['rating'][i] <= 112 :\n",
    "        rating_class.append('class_2')\n",
    "    elif df['rating'][i] <= 197 :\n",
    "        rating_class.append('class_3')\n",
    "    else:\n",
    "        rating_class.append('class_4')\n",
    "\n",
    "print(len(rating_class))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.array(rating_class) == 'class_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact2 = pd.factorize(rating_class)\n",
    "print(fact2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = sorted(list(set(np.arange(5739)) - set([36,\n",
    "96,\n",
    "787,\n",
    "1113,\n",
    "1703,\n",
    "1753,\n",
    "2596,\n",
    "2642,\n",
    "3090,\n",
    "4072,\n",
    "4105,\n",
    "4238,\n",
    "5253,\n",
    "5667])))\n",
    "dataset = Dataset(np.array(ind), fact2[0][ind]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = read_dict(Config.dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([df for i, (string, df, cf) in terms], density=True)\n",
    "plt.title('Document Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([cf for i, (string, df, cf) in terms], density=True)\n",
    "plt.title('Collection Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(dataset.x):\n",
    "    if len(x.shape) != 2:\n",
    "        print(i, dataset.inds[i], x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = max_seg_chi2(terms, dataset, size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_train_f1, mi_train_f1, ma_valid_f1, mi_valid_f1 = cross_validation(clf, dataset, seed=1126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'macro f1 (train): {ma_train_f1}')\n",
    "print(f'micro f1 (train): {mi_train_f1}')\n",
    "print(f'macro f1 (valid): {ma_valid_f1}')\n",
    "print(f'micro f1 (valid): {mi_valid_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(clf, dataset, fold=10, permutation=True, seed=None):\n",
    "  if seed:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "  n = len(dataset)\n",
    "  if permutation:\n",
    "    permute = np.random.permutation(n)\n",
    "  else:\n",
    "    permute = np.arange(n)\n",
    "  width = int(np.ceil(n / fold))\n",
    "  left = 0\n",
    "  right = width\n",
    "  mat = np.zeros((4, 4))\n",
    "  for i in range(fold):\n",
    "    train_permute = np.concatenate((permute[:left], permute[right:]))\n",
    "    test_permute = permute[left:right]\n",
    "#     test_permute = np.concatenate((permute[:left], permute[right:]))\n",
    "#     train_permute = permute[left:right]\n",
    "    left += width\n",
    "    right += width\n",
    "    dataset_train, dataset_test = train_test_split(dataset, train_permute, test_permute)\n",
    "    clf.train(dataset_train)\n",
    "    pred = clf.predict(dataset_test)\n",
    "#     print(min(dataset_test.y), max(dataset_test.y))\n",
    "    for i in range(len(dataset_test)):\n",
    "        mat[pred[i,1]-2, int(dataset_test.y[i]-2)] += 1\n",
    "  mat /= fold\n",
    "  print(mat)\n",
    "  return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(clf, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- safe < euclid < keter\n",
    "- thaumiel\n",
    "- neutralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "print(fact2[1])\n",
    "sns.heatmap(mat, annot=True,  linewidths=.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision')\n",
    "print(fact2[1])\n",
    "print(np.diag(mat) / np.sum(mat, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall')\n",
    "print(fact2[1])\n",
    "print(np.diag(mat) / np.sum(mat, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1')\n",
    "print(fact2[1])\n",
    "p = np.diag(mat) / np.sum(mat, axis=1)\n",
    "r = np.diag(mat) / np.sum(mat, axis=0)\n",
    "f = 2 * p * r / (p + r)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(len(fact2[1]))\n",
    "\n",
    "width = 0.2\n",
    "rects1 = ax.bar(x - width, p, width, label='Precision')\n",
    "rects2 = ax.bar(x, r, width, label='Recall')\n",
    "rects1 = ax.bar(x + width, f, width, label='F1')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by class')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(fact2[1])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df.object_class == 'thaumiel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the selected terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(terms, dtype=object)[np.array(dictionary)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
